{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/CS_dataset.csv' )  # nrows = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to reduce the size of the data:\n",
    "data = data.sample(frac = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data = data.dropna() #drop lines containing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.index == 79695] #Corse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['specialty_subgroup'] #deletes the unuseful column specialty_subgroup\n",
    "del data['id'] #Delete ID which is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set(list(data['zipcode'])) #list of zip codes\n",
    "#len(data[data['no_show']== 1]) #percentage of no_shows in the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient_class = list(data['zipcode'].value_counts().keys())\n",
    "#len(new_patient_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_period_day bucketizes the time in 4 periods of the day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_period_day(time):\n",
    "    if 7 < int(time[0:2]) < 11:\n",
    "        return 0 #morning\n",
    "    if 11 <= int(time[0:2]) <= 14:\n",
    "        return 1 #lunch\n",
    "    if 14 < int(time[0:2]) <= 19:\n",
    "        return 2 #afternoon\n",
    "    else:\n",
    "        return 3 #night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['start'] = data['start'].apply(lambda time: get_period_day(time)) \n",
    "data['created'] = data['created'].apply(lambda time: get_period_day(time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary for \n",
    "zip_region = pd.read_csv('./Data/zip-nom-region.csv', delimiter = ';') #data with the mapping from zip code to region namezip_region.drop_duplicates(inplace = True)\n",
    "zip_region.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_region.index = zip_region['Code Dept']\n",
    "del zip_region['Code Dept']\n",
    "dict_zip_region = zip_region.to_dict()['Nom Region']\n",
    "\n",
    "def return_region(depto_code):\n",
    "    return dict_zip_region[str(depto_code)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_zip_region['98'] = 'Monaco' #????\n",
    "dict_zip_region['97'] = 'La Reunion' #???\n",
    "dict_zip_region['20'] = 'Corse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put LINGOLSHEIM in the same zip department as Strasbourg (67)\n",
    "\n",
    "def get_department(zip_code):\n",
    "    if str(zip_code).split()[0].isdigit(): #'68125 '.split()[0].isdigit()\n",
    "        #print('return ', int(str(zip_code)[0:2]) )\n",
    "        return int(str(zip_code)[0:2])\n",
    "    if zip_code == 'LINGOLSHEIM':\n",
    "        #print('LINGO 67')\n",
    "        return 67\n",
    "    if zip_code == 'L-4048':\n",
    "        return 64 #Aquitaine\n",
    "    else:\n",
    "        print('data type: {} , zip code {}: '.format(type(zip_code) , zip_code))\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zipcode'] = data['zipcode'].apply(lambda code: get_department(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.dropna() #hopefully not necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empy column for regions\n",
    "data['region'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_name(zip_code):\n",
    "    #dept_code = get_department(zip_code)\n",
    "    #print(zip_code)\n",
    "    region = zip_region[zip_region['Code Dept'] == '6']['Nom Region'].item()\n",
    "    #print(\"zipcode: {} , region: {}: \".format(zip_code , region))\n",
    "    return region  #list(zip_region[zip_region['Code Dept'] == '6']['Nom Region'])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['region'] = data['zipcode'].apply(lambda code: return_region(code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's encode the columns that are not numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient_dummy = pd.get_dummies(data['new_patient'], prefix=['new_patient']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The missing data isn't taken into account (NaN). Should we add it anyways ?\n",
    "is_relative_dummy =  pd.get_dummies(data['is_relative'], prefix=['is_relative']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_device_dummy = pd.get_dummies(data['booking_device'], prefix=['booking_device']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_type_dummy = pd.get_dummies(data['organization_type'], prefix=['organization_type']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_age_group_dummy = pd.get_dummies(data['patient_age_group'], prefix=['patient_age_group']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_motive_name_dummy = pd.get_dummies(data['visit_motive_name'], prefix=['visit_motive_name']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dummy =  pd.get_dummies(data['month'], prefix=['month']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dummy = pd.get_dummies(data['day'], prefix=['day']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dummy = pd.get_dummies(data['start'], prefix=['start']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_dummy = pd.get_dummies(data['created'], prefix=['created']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dummy = pd.get_dummies(data['region'], prefix=['region']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['new_patient', 'is_relative', 'booking_device', 'organization_type', 'patient_age_group', 'visit_motive_name', 'month', 'day', 'start', 'created', 'region'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we concatenate them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketized_df = pd.concat([data, patient_age_group_dummy, visit_motive_name_dummy,organization_type_dummy,booking_device_dummy, is_relative_dummy,new_patient_dummy, month_dummy, day_dummy, start_dummy,created_dummy, region_dummy], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save them to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketized_df.to_csv('encoded_data_5%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
